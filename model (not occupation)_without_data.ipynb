{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tah Plen\n",
    "\n",
    "for each feature and each label...\n",
    "- model (simplify) the data to known distributions (gaussian, etc)\n",
    "- calculate probability that input data (single feature) fits to given distribution\n",
    "\n",
    "analyzing probability through multiple feature and label are expected to give prediction in method such as... (what should be done after this)\n",
    "- for each feature, calculate each probability where it belongs to 0 or 1 and multiply them for each class\n",
    "- assume the class only based on if probability exceed certain threshold for certain class\n",
    "- and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so for this code,\n",
    "\n",
    "when making a model...\n",
    "\n",
    "input requires two lists as below\n",
    "\n",
    "    [list of values in single feature with class 0], [\" with class 1] (, might have more inputs to define model like defining (assuming) distribution)\n",
    "\n",
    "and output will be a \n",
    "    \n",
    "    list/dictionary that summerizes the distribution\n",
    "\n",
    "(it will feed directly to below without going anywhere, so i'll take this on my own)\n",
    "\n",
    "when making a prediction...\n",
    "\n",
    "input includes\n",
    "    \n",
    "    data to predict, a summarized model\n",
    "\n",
    "output will be a list with two elements\n",
    "\n",
    "    [probability of data included in class 0, \" class 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note about bayes\n",
    "\n",
    "P( has specific lable | has specific value ) = P( has specific value | has specific label ) * P( has specific label ) / P( has specific value )\n",
    "\n",
    "- interest: P( label | value )\n",
    "\n",
    "\n",
    "- P( value | label ): from modeling the data distribution with specific label\n",
    "- P( label ): from ratio\n",
    "- P( value ): from modeling the whole data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mean(numbers: list) -> float:\n",
    "    \"\"\"Bayes: Calculate the mean of a list of numbers\n",
    "    \n",
    "    Requires math library\n",
    "    \n",
    "    from machinelearningmastery\"\"\"\n",
    "    \n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers: list) -> float:\n",
    "    \"\"\"Bayes: Calculate the standard deviation of a list of numbers\n",
    "    \n",
    "    Requires math library\n",
    "    \n",
    "    from machinelearningmastery\"\"\"\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize_gaussian(numbers: list) -> dict:\n",
    "    \"\"\"Bayes: Calculate the mean, stdev, and len for numbers which is a summerized gaussian model\n",
    "    \n",
    "    Requires math library and means, stdev function\n",
    "    \n",
    "    modified from machinelearningmastery\"\"\"\n",
    "    summaries = {'model': 'gaussian', 'mean': mean(numbers), 'stdev': stdev(numbers), 'len': len(numbers)}\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_gaussian(x: float, mean: float, stdev: float) -> float:\n",
    "    \"\"\"Bayes: Calculate the Gaussian probability distribution function for x\n",
    "    \n",
    "    Requires math library\n",
    "    \n",
    "    from machinelearningmastery\"\"\"\n",
    "    exponent = math.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    " \n",
    "def calculate_class_probabilities(target: float, total_summary: dict, label0_summary: dict, label1_summary: dict) -> tuple:\n",
    "    \"\"\"Bayes: Calculate the probabilities of target belong in label0 and label1\n",
    "    \n",
    "    Requires calculate_probability_gaussian function\"\"\"\n",
    "    # if model != gaussian -> return -1\n",
    "    px0 = calculate_probability_gaussian(target, label0_summary['mean'], label0_summary['stdev'])\n",
    "    px1 = calculate_probability_gaussian(target, label1_summary['mean'], label1_summary['stdev'])\n",
    "    p0 = label0_summary['len'] / total_summary['len']\n",
    "    p1 = label1_summary['len'] / total_summary['len']\n",
    "    px = calculate_probability_gaussian(target, total_summary['mean'], total_summary['stdev'])\n",
    "    p0x = px0 * p0 / px\n",
    "    p1x = px1 * p1 / px\n",
    "    return p0x, p1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thatfunctionthatconsiderspossibilityofmultiplefeatureandchoosetheclasswhichgivendatabelongstoandalsohascomicallylongname(probabilities: list, debug: int = 0) -> int: # bias: list = [],\n",
    "    \"\"\"Bayes: Calculates combinations of possibilities that certain value belongs to each features while not others\n",
    "    \n",
    "    Add each probability for when each class is dominant and compare the value in order to predict the label\n",
    "    \n",
    "    probabilities\n",
    "        list of tuples from calculate_class_probabilities\n",
    "    \n",
    "    debug\n",
    "        when value is 1, print the values of each possibilities and other detailed statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # 예시: 5개의 feature 중 예측된 레이블이 각 feature 순서대로 첫 2개에서 0, 뒷 3개에서 1이라고 예측했을 때 실제 값이 0일 확률은\n",
    "    # (1번 레이블에서 0이라고 예측한 게 맞을 확률) * (2번 \") * (3번 레이블에서 1이라고 예측한 게 틀릴 확률) * ...\n",
    "    # 틀릴 확률 = 1 - 맞을 확률\n",
    "    \n",
    "    # bias (X)\n",
    "    #     Use to multiply the consideration to certain feature\n",
    "        \n",
    "    #     when [1, 1, 2, 1, 1], third feature will be considered twice than other features\n",
    "    \n",
    "    iszero = 0\n",
    "    isone = 0\n",
    "    featurecount = len(probabilities)\n",
    "    \n",
    "    # if len(bias) != featurecount:\n",
    "    #     bias = [1] * featurecount\n",
    "    \n",
    "    # if debug == 1:\n",
    "    #     for b in range(len(bias)):\n",
    "    #         if b != 1:\n",
    "    #             print(f\"bias in feature #{b}: x{bias[b]}\")\n",
    "    \n",
    "    for i in range(0, 2**featurecount):\n",
    "        currentcombination = eval(\"'{:0>\" + str(featurecount) + \"}'.format(bin(\" + str(i) + \")[2:])\")\n",
    "        iscurrentcombinationofzero = 1\n",
    "        iscurrentcombinationofone = 1\n",
    "        for j in range(featurecount):\n",
    "            if currentcombination[j] == '0':\n",
    "                iscurrentcombinationofzero *= probabilities[j][0] # * bias[j]\n",
    "                iscurrentcombinationofone *= (1 - probabilities[j][0])\n",
    "            else:\n",
    "                iscurrentcombinationofzero *= (1 - probabilities[j][1]) # * bias[j]\n",
    "                iscurrentcombinationofone *= probabilities[j][1]\n",
    "        iszero += iscurrentcombinationofzero\n",
    "        isone += iscurrentcombinationofone\n",
    "        if debug:\n",
    "            print(f\"combination: {currentcombination} | probability of label being 0 {iscurrentcombinationofzero}\")\n",
    "            print(\" \" * len(f\"combination: {currentcombination} \") + f\"| probability of label being 0 {iscurrentcombinationofone}\")\n",
    "    if debug:\n",
    "        print(f\"total probability of being 0: {iszero}\")\n",
    "        print(f\"total probability of being 1: {isone}\")\n",
    "    if iszero >= isone:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize_multiple_features(featured: list) -> list:\n",
    "    \"\"\"Bayes: summerize each feature in featured with gaussian and return list of summerized models\n",
    "    \n",
    "    Requires summerize gaussian function\n",
    "    \n",
    "    elements of returned list is a list with three elements, each are summary of total data, data with label 0, and data with label 1\"\"\"\n",
    "    model_summeries = []\n",
    "\n",
    "    for feature_no in range(len(featured)):\n",
    "        labelzero = summarize_gaussian(featured[feature_no][0])\n",
    "        labelone = summarize_gaussian(featured[feature_no][1])\n",
    "        total = labelzero + labelone\n",
    "        labeltotal = summarize_gaussian(total)\n",
    "        model_summeries.append([labeltotal, labelzero, labelone])\n",
    "    \n",
    "    return model_summeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of input when training model\n",
    "# featured_example = [[['values of feature #1 when label = 0'], ['values of feature #1 when label = 1']], [['values of feature #2 when label = 0'], ['values of feature #2 when label = 1']], ['...']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelmaking\n",
    "\n",
    "datas_example = [] #featured_example-like data\n",
    "\n",
    "summeries_example = summerize_multiple_features(datas_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting single data\n",
    "\n",
    "input_to_predict = ['value of feature 1', 'value of feature 2', '...'] # values of feature here\n",
    "\n",
    "if len(input_to_predict) != len(summeries_example):\n",
    "    print(\"Bayes: number of feature does not match!\")\n",
    "\n",
    "perchance = []\n",
    "\n",
    "for featurenum in summeries_example:\n",
    "    perchance.append(calculate_class_probabilities(input_to_predict[featurenum], summeries[featurenum][0], summeries[featurenum][1], summeries[featurenum][2]))\n",
    "\n",
    "print(thatfunctionthatconsiderspossibilityofmultiplefeatureandchoosetheclasswhichgivendatabelongstoandalsohascomicallylongname(perchance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data: list, summary: list) -> int:\n",
    "    \"\"\"Bayes: predict the label of single sets of data when summary\"\"\"\n",
    "    \n",
    "    if len(data) != len(summary):\n",
    "        print(\"Bayes: number of feature does not match!\")\n",
    "        return -1\n",
    "\n",
    "    perchance = []\n",
    "\n",
    "    for featurenum in summary:\n",
    "        perchance.append(calculate_class_probabilities(input_to_predict[featurenum], summary[featurenum][0], summary[featurenum][1], summary[featurenum][2]))\n",
    "\n",
    "    return thatfunctionthatconsiderspossibilityofmultiplefeatureandchoosetheclasswhichgivendatabelongstoandalsohascomicallylongname(perchance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(datas: list, summary: list) -> list:\n",
    "    \"\"\"Bayes: predict multiple datas and return the values as list\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for data in datas:\n",
    "        predictions.append(predict(data, summary))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(original_label: list, predicted_label: list) -> float, float, float, float:\n",
    "    if len(original_label) != len(predicted_label):\n",
    "        return -1\n",
    "    \n",
    "    # positive = 1 / negative = 0\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for i in range(len(original_label)):\n",
    "        if original_label[i] == predicted_label[i]:\n",
    "            if predicted_label[i] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if predicted_label[i] == 1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "                \n",
    "    pre = TP / (TP + FP)\n",
    "    rec = TP / (TP + FN)\n",
    "    acc = (TP + TN) / (TP + FN + FP + TN)\n",
    "    f1 = 2 * pre * rec / (pre + rec)\n",
    "    \n",
    "    print(f\"precision: {pre}\")\n",
    "    print(f\"recall: {rec}\")\n",
    "    print(f\"accuracy: {acc}\")\n",
    "    print(f\"f1-score: {f1}\")\n",
    "    \n",
    "    return pre, rec, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_1_data = []\n",
    "\n",
    "answersheet = [0] * len(feature_set_1_data[0][0]) + [1] * len(feature_set_1_data[0][1])\n",
    "\n",
    "summeries = summerize_multiple_features(feature_set_1_data)\n",
    "\n",
    "calculate_f1(answersheet, predict_multiple(feature_set_1_data, summeries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_2_data = []\n",
    "\n",
    "answersheet2 = [0] * len(feature_set_2_data[0][0]) + [1] * len(feature_set_2_data[0][1])\n",
    "\n",
    "summeries2 = summerize_multiple_features(feature_set_2_data)\n",
    "\n",
    "calculate_f1(answersheet2, predict_multiple(feature_set_2_data, summeries2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
